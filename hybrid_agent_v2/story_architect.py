import os
import json
import time
import re
import subprocess
from pathlib import Path
from google import genai
from google.genai import types
from config import load_api_key, get_all_api_keys
from presets.factory_config import FactoryConfig
from .llm_interface import LLMInterface
from .knowledge_base import VideoKnowledgeBase
from .visual_scout import VisualScout
from .rejection_analyst import RejectionAnalyst

class StoryArchitect:
    def __init__(self):
        load_api_key()
        self.api_keys = get_all_api_keys()
        self.model_name = "gemini-1.5-flash-latest" # ‚úÖ V5: 404 Ìï¥Í≤∞ÏùÑ ÏúÑÌïú Fallback ID
        self.client = genai.Client(api_key=self.api_keys[0])
        self.rejection_log = Path("rejected_stories.json")
        self.scout = VisualScout()
        self.ra = RejectionAnalyst()

    def _safe_parse_json(self, raw_text):
        """
        ‚úÖ FIX: Í∞ïÌôîÎêú JSON ÌååÏã± (ÎßàÌÅ¨Îã§Ïö¥ ÏΩîÎìúÎ∏îÎ°ù, Ï£ºÏÑù, Î∂àÏôÑÏ†ÑÌïú JSON Ï≤òÎ¶¨)
        """
        if not raw_text:
            return None
        
        # 1. ÎßàÌÅ¨Îã§Ïö¥ ÏΩîÎìúÎ∏îÎ°ù Ï†úÍ±∞ (```json ... ``` ÎòêÎäî ``` ... ```)
        text = re.sub(r'```json\s*', '', raw_text)
        text = re.sub(r'```\s*', '', text)
        
        # 2. JSON Í∞ùÏ≤¥/Î∞∞Ïó¥ Ï∂îÏ∂ú ÏãúÎèÑ
        json_match = re.search(r'(\{[\s\S]*\}|\[[\s\S]*\])', text)
        if json_match:
            text = json_match.group(1)
        
        # 3. Ï£ºÏÑù Ï†úÍ±∞ (// ... ÎòêÎäî /* ... */)
        text = re.sub(r'//.*?\n', '\n', text)
        text = re.sub(r'/\*.*?\*/', '', text, flags=re.DOTALL)
        
        # 4. ÌååÏã± ÏãúÎèÑ
        try:
            return json.loads(text)
        except json.JSONDecodeError as e:
            print(f"[StoryArchitect] ‚ö†Ô∏è JSON Parse Error at position {e.pos}: {e.msg}")
            print(f"[StoryArchitect] üìÑ Raw response preview: {raw_text[:500]}...")
            
            # 5. ÎßàÏßÄÎßâ ÏãúÎèÑ: Î∂àÏôÑÏ†ÑÌïú JSON ÏàòÏ†ï (ÎßàÏßÄÎßâ ÏâºÌëú, Îã´ÌûàÏßÄ ÏïäÏùÄ Í¥ÑÌò∏)
            try:
                # ÎßàÏßÄÎßâ ÏâºÌëú Ï†úÍ±∞
                text = re.sub(r',\s*([\]}])', r'\1', text)
                # Îã´ÌûàÏßÄ ÏïäÏùÄ Î∞∞Ïó¥/Í∞ùÏ≤¥ Îã´Í∏∞
                if text.count('{') > text.count('}'):
                    text += '}' * (text.count('{') - text.count('}'))
                if text.count('[') > text.count(']'):
                    text += ']' * (text.count('[') - text.count(']'))
                return json.loads(text)
            except:
                return None

    def _summarize_transcript_in_chunks(self, transcript, video_id, max_chunk_chars=20000):
        """
        Í∏¥ ÎåÄÎ≥∏ÏùÑ Ï≤≠ÌÅ¨Î°ú ÎÇòÎà† Í∞ÅÍ∞Å ÏöîÏïΩ ÌõÑ Î≥ëÌï© (12ÏãúÍ∞Ñ+ Ïû•Ìé∏ ÏòÅÏÉÅ ÎåÄÏùë)
        """
        from google.genai import types
        import time
        
        # 1. Ï≤≠ÌÅ¨ Î∂ÑÌï† (Ï§ÑÎ∞îÍøà Í∏∞Ï§Ä)
        chunks = []
        lines = transcript.split('\n')
        current_chunk = []
        current_length = 0
        
        for line in lines:
            line_len = len(line)
            if current_length + line_len > max_chunk_chars and current_chunk:
                chunks.append('\n'.join(current_chunk))
                current_chunk = [line]
                current_length = line_len
            else:
                current_chunk.append(line)
                current_length += line_len
        
        if current_chunk:
            chunks.append('\n'.join(current_chunk))
        
        print(f"[StoryArchitect] üìö Split into {len(chunks)} chunks for summarization")
        
        # 2. Í∞Å Ï≤≠ÌÅ¨ÏóêÏÑú Ïù¥Î≤§Ìä∏ Ï∂îÏ∂ú
        all_events = []
        for i, chunk in enumerate(chunks):
            try:
                prompt = f"""
ÏòÅÏÉÅ ÎåÄÎ≥∏ÏóêÏÑú Ï§ëÏöîÌïú 'ÏÉÅÌÉú Î≥ÄÌôî'Îßå Î°úÍ∑∏ ÌòïÌÉúÎ°ú Ï∂îÏ∂úÌïòÎùº.
ÎåÄÎ≥∏ÏùÑ ÏöîÏïΩÌïòÍ±∞ÎÇò ÏÑ§Î™ÖÌïòÏßÄ ÎßàÏã≠ÏãúÏò§.

# Ï∂îÏ∂ú ÎåÄÏÉÅ (Event Types):
1. Game Start/End/Reset: Í≤åÏûÑÏùò ÏãúÏûë, Ï¢ÖÎ£å, Ïû¨ÏãúÎèÑ ÏßÄÏ†ê
2. Topic Change: ÎåÄÌôî Ï£ºÏ†úÎÇò Î∞©ÏÜ° Î∂ÑÏúÑÍ∏∞Í∞Ä Í∏âÍ≤©Ìûà Î≥ÄÌïòÎäî ÏßÄÏ†ê
3. High Reaction: ÎπÑÎ™Ö, ÌÅ∞ Ìè≠ÏÜå, Î∂ÑÎÖ∏ Îì± Í∞êÏ†ïÏù¥ Ìè≠Î∞úÌïòÎäî ÏßÄÏ†ê

# ÎåÄÎ≥∏ Ï≤≠ÌÅ¨ #{i+1}/{len(chunks)}:
{chunk[:8000]}

# OUTPUT FORMAT (JSON Array):
[
  {{"time": float, "event": "Ïù¥Î≤§Ìä∏ Ï¢ÖÎ•ò", "importance": 1~10}}
]
Î∞òÎìúÏãú Ïú†Ìö®Ìïú JSON Î∞∞Ïó¥Îßå Ï∂úÎ†•ÌïòÏã≠ÏãúÏò§.
"""
                # ‚úÖ FIX: Ìò∏Ï∂ú Í∞ÑÍ≤© 2Ï¥à (V5 Í∞ÄÏù¥Îìú)
                time.sleep(2)
                
                print(f"DEBUG: StoryArchitect Current Model ID -> {self.model_name}")
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=prompt,
                    config=types.GenerateContentConfig(temperature=0.2, response_mime_type="application/json")
                )
                
                chunk_events = self._safe_parse_json(response.text)
                if isinstance(chunk_events, list):
                    all_events.extend(chunk_events)
                    print(f"   ‚úÖ Chunk {i+1}/{len(chunks)} extracted {len(chunk_events)} events")
                else:
                    print(f"   ‚ö†Ô∏è Chunk {i+1} returned invalid format, skipping")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Chunk {i+1} failed: {e}")
                # ‚úÖ V5: ÌïòÎÇòÎùºÎèÑ Ïã§Ìå®Ìï¥ÎèÑ Ï§ëÎã®ÌïòÏßÄ ÏïäÍ≥† Îã§Ïùå Ï≤≠ÌÅ¨Î°ú ÏßÑÌñâ
                continue
        
        if not all_events:
            print("[StoryArchitect] ‚ùå All chunks failed to extract events. Returning empty list.")
        else:
            print(f"[StoryArchitect] ‚úÖ Extracted {len(all_events)} total events from successfully processed chunks")
        
        return all_events

    def segment_and_rank(self, video_path, transcript, top_n=3, video_id="temp", visual_data=None):
        """
        [Macro Architect] Ï†ÑÏ≤¥ ÎåÄÎ≥∏ + ÏãúÍ∞ÅÏ†Å ÏóêÎÑàÏßÄÎ•º Î∂ÑÏÑùÌïòÏó¨ 'Ìåê'ÏùÑ ÎÇòÎàÑÍ≥† Îû≠ÌÇπÏùÑ Îß§ÍπÅÎãàÎã§.
        """
        print(f"\nüè∞ [Macro Architect] Starting Narrative Search for '{video_id}'...")
        
        # 1. Visual Analysis
        if visual_data is None and not getattr(FactoryConfig, 'SKIP_VISUAL', False):
            visual_data = self.scout.analyze_video(video_path)
            
        visual_peaks = self._get_high_energy_points(visual_data) if visual_data else []
        peaks_str = ", ".join([f"{p['time']:.1f}s({p['type']})" for p in visual_peaks[:15]])

        # ‚úÖ FIX: ÎåÄÎ≥∏ Í∏∏Ïù¥ Ï†úÌïú (Ï≤≠ÌÅ¨ ÏöîÏïΩ Î∞©Ïãù)
        max_transcript_len = 30000  # ~10k tokens
        # ‚úÖ FIX: ÎåÄÎ≥∏ Í∏∏Ïù¥ Ï†úÌïú (V5: Ïù¥Î≤§Ìä∏ Î°úÍ∑∏ Î∞©Ïãù)
        if len(transcript) > 20000:
            print(f"[StoryArchitect] üìö Transcript too long ({len(transcript)} chars)")
            print(f"[StoryArchitect] üîÑ Extracting Event Logs from chunks...")
            event_logs_str = self._summarize_transcript_in_chunks(transcript, video_id)
        else:
            event_logs_str = transcript # ÏßßÏúºÎ©¥ Í∑∏ÎåÄÎ°ú (Í±∞Ïùò ÏóÜÏùå)

        prompt = f"""
# ROLE: Í≥†ÎèÑÎ°ú ÏàôÎ†®Îêú ÏòÅÏÉÅ Ïä§ÌÜ†Î¶¨ Ìé∏ÏßëÏûê
# TASK: Ï∂îÏ∂úÎêú 'Ïù¥Î≤§Ìä∏ Î°úÍ∑∏'ÏôÄ 'ÏãúÍ∞ÅÏ†Å ÌîºÌÅ¨' Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú, ÏòÅÏÉÅÏùò Í±∞ÏãúÏ†Å Íµ¨Ï°∞Î•º 'Ìåê(Match)' ÎòêÎäî 'Ï±ïÌÑ∞'Î°ú Î∂ÑÌï†ÌïòÎùº.

# Ï∂îÏ∂úÎêú Ïù¥Î≤§Ìä∏ Î°úÍ∑∏ (Event Logs - V5):
{event_logs_str}

# ÏãúÍ∞ÅÏ†Å Í∞ïÏ°∞ ÏßÄÏ†ê (Visual High-Energy Points):
{peaks_str if peaks_str else "No major visual peaks detected."}

# üß† LESSONS FROM THE PAST:
{self.ra.get_editing_feedback(limit=5)}

# CRITICAL: Ïù¥Î≤§Ìä∏ Î°úÍ∑∏Ïùò Î∞úÏÉù ÏãúÍ∞ÑÏùÑ Í∏∞Ï§ÄÏúºÎ°ú Ï±ïÌÑ∞Ïùò ÏãúÏûëÍ≥º ÎÅùÏùÑ Ï†ïÌïòÏã≠ÏãúÏò§. 
# Î∞òÎìúÏãú Ïú†Ìö®Ìïú JSONÎßå Ï∂úÎ†•ÌïòÍ≥†, Ï£ºÏÑùÏù¥ÎÇò ÎßàÌÅ¨Îã§Ïö¥ÏùÄ Í∏àÏßÄÌï©ÎãàÎã§.

# OUTPUT FORMAT (Pure JSON Only):
{{
  "chapters": [
    {{
      "id": 1,
      "title": "Ï±ïÌÑ∞ Ï†úÎ™©",
      "start_time": 0.0,
      "end_time": 600.0,
      "narrative_score": 9.5,
      "summary": "ÏÑúÏÇ¨Ï†Å ÏöîÏïΩ Î∞è Ïù¥Î≤§Ìä∏ Í∑ºÍ±∞",
      "is_boring": false
    }}
  ]
}}
"""

        max_retries = 3
        for attempt in range(max_retries):
            try:
                # ‚úÖ FIX: Ìò∏Ï∂ú Í∞ÑÍ≤© 2Ï¥à (V5 Í∞ÄÏù¥Îìú)
                time.sleep(2)
                
                print(f"DEBUG: StoryArchitect Segment Current Model ID -> {self.model_name}")
                # ‚úÖ FIX: temperature ÎÇÆÏ∂∞ÏÑú JSON ÌòïÏãù Ï§ÄÏàòÏú® Ìñ•ÏÉÅ
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        response_mime_type="application/json",
                        temperature=0.2  # 0.4 -> 0.2Î°ú ÎÇÆÏ∂§
                    )
                )
                
                # ‚úÖ FIX: ÏïàÏ†ÑÌïú ÌååÏã±
                result = self._safe_parse_json(response.text)
                
                if result is None:
                    raise ValueError("Failed to parse JSON response")
                
                all_chapters = result.get('chapters', [])
                
                if not all_chapters:
                    print(f"[StoryArchitect] ‚ö†Ô∏è No chapters returned (Attempt {attempt+1}/{max_retries})")
                    if attempt < max_retries - 1:
                        time.sleep(2)
                        continue
                    else:
                        return []  # FallbackÏúºÎ°ú ÎÑòÍπÄ
                
                # 1. Logging Rejections
                self._log_rejections(all_chapters)
                
                # 2. Ranking & Filtering
                valid_chapters = [c for c in all_chapters if not c.get('is_boring', False)]
                
                if not valid_chapters:
                    print(f"[StoryArchitect] ‚ö†Ô∏è All chapters marked as boring!")
                    # Í∑∏ÎûòÎèÑ ÏÉÅÏúÑ NÍ∞úÎäî Í∞ÄÏ†∏Í∞ÄÍ∏∞
                    valid_chapters = sorted(all_chapters, key=lambda x: x.get('narrative_score', 0), reverse=True)[:top_n]
                
                ranked = sorted(valid_chapters, key=lambda x: x.get('narrative_score', 0), reverse=True)
                selection = ranked[:top_n]
                
                # Í∞Å Ï±ïÌÑ∞Ïóê ÏãúÍ∞ÅÏ†Å Îç∞Ïù¥ÌÑ∞ Î∂ôÏù¥Í∏∞
                for s in selection: 
                    s['visual_context'] = visual_data
                
                print(f"‚úÖ Selected TOP {len(selection)} Macro-Chapters based on Narrative & Visual Ranking.")
                return selection
                
            except Exception as e:
                print(f"üö® Macro-Segmentation Ïò§Î•ò (Attempt {attempt+1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    print(f"   üîÑ Retrying in 3 seconds...")
                    time.sleep(3)
                else:
                    print(f"   ‚ùå Max retries reached. Falling back to signal analysis.")
                    return []

    def _get_high_energy_points(self, visual_data, threshold=0.7):
        """ÏãúÍ∞ÅÏ†Å ÏóêÎÑàÏßÄÍ∞Ä ÎÜíÏùÄ ÏßÄÏ†êÎì§ÏùÑ Ï∂îÏ∂ú"""
        if not visual_data: return []
        peaks = []
        energy = visual_data['visual_energy']
        times = visual_data['times']
        
        for i in range(1, len(energy)-1):
            if energy[i] > threshold and energy[i] > energy[i-1] and energy[i] > energy[i+1]:
                p_type = "Action" if visual_data['motion'][i] > visual_data['entropy'][i] else "Detail"
                peaks.append({"time": float(times[i]), "score": float(energy[i]), "type": p_type})
        
        return sorted(peaks, key=lambda x: x['score'], reverse=True)

    def identify_micro_points(self, chapter_data, chapter_transcript):
        """
        [Micro Editor]
        ÏÑ†Ï†ïÎêú Ï±ïÌÑ∞ ÎÇ¥Î∂ÄÏóêÏÑú ÌïµÏã¨ Ìè¨Ïù∏Ìä∏(ÏãúÏûë/ÏúÑÍ∏∞/Í≤∞Í≥º)Î•º Ï∞çÏäµÎãàÎã§.
        """
        print(f"   üé¨ Micro-Editing Match: '{chapter_data['title']}'...")
        
        # ‚úÖ FIX: Ï±ïÌÑ∞ ÏãúÍ∞Ñ Î≤îÏúÑ Î™ÖÏãú
        c_start = float(chapter_data.get('start_time', 0))
        c_end = float(chapter_data.get('end_time', c_start + 600))
        
        prompt = f"""
# ROLE: ÏòÅÏÉÅ Ïª∑ Ìé∏Ïßë Ï†ÑÎ¨∏Í∞Ä
# TASK: ÏïÑÎûò Ï±ïÌÑ∞Ïùò ÎåÄÎ≥∏ÏùÑ Î∂ÑÏÑùÌïòÏó¨ ÏÑúÏÇ¨Î•º Íµ¨ÏÑ±ÌïòÎäî 3ÎåÄ ÌïµÏã¨ ÏßÄÏ†êÍ≥º Î∏åÎ¶øÏßÄ ÏûêÎßâÏùÑ ÏÉùÏÑ±ÌïòÎùº.

# CHAPTER INFO:
- Title: {chapter_data['title']}
- Time Range: {c_start:.1f}s ~ {c_end:.1f}s
- Context: {chapter_data['summary']}

# CHAPTER TRANSCRIPT:
{chapter_transcript[:5000]}

# CRITICAL RULES:
1. **ÏãúÍ∞Ñ(time)ÏùÄ Î∞òÎìúÏãú Ï±ïÌÑ∞ Î≤îÏúÑ {c_start:.1f}~{c_end:.1f} ÎÇ¥Ïùò Ï¥à Îã®ÏúÑ Ïà´ÏûêÏó¨Ïïº Ìï®**
2. **Î∞òÎìúÏãú Ïú†Ìö®Ìïú JSONÎßå Ï∂úÎ†•**
3. **ÏÑ∏ Í∞úÏùò Ìè¨Ïù∏Ìä∏(start, crisis, result)Î•º Î™®Îëê Ìè¨Ìï®Ìï† Í≤É**

# OUTPUT FORMAT (Pure JSON Only):
{{
  "points": {{
    "start": {{"time": {c_start + 10}, "reason": "ÏÉÅÌô©Ïùò ÏãúÏûë"}},
    "crisis": {{"time": {(c_start + c_end) / 2}, "reason": "Í∞àÎì±Ïùò Ï†àÏ†ï"}},
    "result": {{"time": {c_end - 10}, "reason": "ÏµúÏ¢Ö Í≤∞Í≥º"}}
  }},
  "bridge_text": "Ïó∞Í≤∞ Î©îÏãúÏßÄ"
}}
"""

        max_retries = 2
        for attempt in range(max_retries):
            try:
                # ‚úÖ FIX: Ìò∏Ï∂ú Í∞ÑÍ≤© 2Ï¥à (V5 Í∞ÄÏù¥Îìú)
                time.sleep(2)
                
                print(f"DEBUG: StoryArchitect Micro Current Model ID -> {self.model_name}")
                response = self.client.models.generate_content(
                    model=self.model_name,
                    contents=prompt,
                    config=types.GenerateContentConfig(
                        response_mime_type="application/json",
                        temperature=0.2
                    )
                )
                
                result = self._safe_parse_json(response.text)
                
                # ‚úÖ FIX: Í≤∞Í≥º Í≤ÄÏ¶ù
                if result is None:
                    print(f"   ‚ö†Ô∏è Failed to parse JSON (Attempt {attempt+1}/{max_retries})")
                    continue
                
                if 'points' not in result:
                    print(f"   ‚ö†Ô∏è No 'points' key in response (Attempt {attempt+1}/{max_retries})")
                    continue
                
                points = result['points']
                if not all(k in points for k in ['start', 'crisis', 'result']):
                    print(f"   ‚ö†Ô∏è Missing required points (Attempt {attempt+1}/{max_retries})")
                    continue
                
                # ÏÑ±Í≥µ!
                return result
                
            except Exception as e:
                print(f"   üö® Micro-Editing Ïò§Î•ò (Attempt {attempt+1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(5) # Ïû¨ÏãúÎèÑ Ïãú Ï∂©Î∂ÑÌïú ÎåÄÍ∏∞ ÏãúÍ∞Ñ ÌôïÎ≥¥
        
        # ‚úÖ FIX: Î™®Îì† Ïû¨ÏãúÎèÑ Ïã§Ìå® Ïãú None Î¶¨ÌÑ¥ (Ïò§Ïóº Î∞©ÏßÄ Î∞è factory_mainÏóêÏÑú ÏïàÏ†ÑÌïòÍ≤å Ïä§ÌÇµ Ïú†ÎèÑ)
        return None

    def _log_rejections(self, chapters):
        """Î≤ÑÎ†§ÏßÑ ÌåêÎì§ÏùÑ Í∏∞Î°ù"""
        rejections = [c for c in chapters if c.get('is_boring')]
        if not rejections: return

        existing_data = []
        if self.rejection_log.exists():
            try:
                with open(self.rejection_log, "r", encoding="utf-8") as f:
                    existing_data = json.load(f)
            except: 
                existing_data = []
            
        for r in rejections:
            r['timestamp'] = time.strftime('%Y-%m-%d %H:%M:%S')
            existing_data.append(r)
            
        try:
            with open(self.rejection_log, "w", encoding="utf-8") as f:
                json.dump(existing_data, f, indent=2, ensure_ascii=False)
            print(f"[StoryArchitect] üóëÔ∏è Logged {len(rejections)} rejected chapters for future learning.")
        except Exception as e:
            print(f"[StoryArchitect] ‚ö†Ô∏è Failed to save rejection log: {e}")
