import os
import json
import re
import time
from google import genai
from google.genai import types
from config import load_api_key

class LLMInterface:
    def __init__(self):
        load_api_key()

        self.api_keys = self._get_ordered_keys()
        if not self.api_keys:
            raise RuntimeError("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤")

        self.current_key_idx = 0
        self.disabled_keys = set()

        # âœ… [ì—…ê·¸ë ˆì´ë“œ] í™•ì¸ëœ 2.5 ëª¨ë¸ì„ ìµœìš°ì„ ìœ¼ë¡œ, 1.5ë¥¼ ë°±ì—…ìœ¼ë¡œ ì„¤ì •
        self.model_candidates = [
            "models/gemini-2.5-flash",
            "models/gemini-2.0-flash",
            "models/gemini-1.5-flash",
        ]

        self.client = None
        self._configure_genai()

    def _get_ordered_keys(self):
        keys = []
        primary = os.environ.get("GOOGLE_API_KEY")
        if primary:
            keys.append(primary)

        numbered = []
        for k, v in os.environ.items():
            if k.startswith("GOOGLE_API_KEY_"):
                try:
                    idx = int(k.split("_")[-1])
                    numbered.append((idx, v))
                except ValueError:
                    continue

        numbered.sort()
        keys.extend([v for _, v in numbered if v])
        return keys

    def _configure_genai(self):
        key = self.api_keys[self.current_key_idx]
        self.client = genai.Client(api_key=key)
        print(f"[LLM] ğŸ”‘ Key #{self.current_key_idx + 1} í™œì„±í™” (ë‚¨ì€ í‚¤: {len(self.api_keys) - len(self.disabled_keys)})")

    def _rotate_key(self):
        for _ in range(len(self.api_keys)):
            self.current_key_idx = (self.current_key_idx + 1) % len(self.api_keys)
            key = self.api_keys[self.current_key_idx]

            if key not in self.disabled_keys:
                self._configure_genai()
                return

        raise RuntimeError("âŒ ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")

    def analyze_full_session(self, full_transcript):
        # 7ë§Œ ì ë¶„ì„ ì‹œ 2ë§Œ ì ì²­í¬ëŠ” ë§¤ìš° ì ì ˆí•©ë‹ˆë‹¤.
        chunk_size = 20000
        chunks = [
            full_transcript[i:i + chunk_size]
            for i in range(0, len(full_transcript), chunk_size)
        ]

        print(f"[LLM] ğŸ“¦ {len(full_transcript):,}ì â†’ {len(chunks)}ê°œ íŒŒíŠ¸ ë¶„ì„ ì‹œì‘")
        all_highlights = []

        for i, chunk in enumerate(chunks):
            print(f"\n[LLM] ğŸ”„ íŒŒíŠ¸ {i + 1}/{len(chunks)} ë¶„ì„ ì¤‘...")
            
            result = self._run_with_retry(chunk)
            highlights = result.get("highlights", [])

            if highlights:
                all_highlights.extend(highlights)
                print(f"   âœ… {len(highlights)}ê°œ ë°œê²¬ (ëˆ„ì : {len(all_highlights)}ê°œ)")
                for h in highlights:
                    print(f"      - {h.get('start')} | {h.get('reason', '')[:40]}")
            else:
                print("   âš ï¸ í•˜ì´ë¼ì´íŠ¸ ì—†ìŒ")

            # ë¬´ë£Œ í‹°ì–´ ì•ˆì •ì„±ì„ ìœ„í•´ 10ì´ˆ íœ´ì‹
            if i < len(chunks) - 1:
                time.sleep(10)

        return {"highlights": all_highlights}

    def _run_with_retry(self, text, max_attempts=3):
        # [ì—…ê·¸ë ˆì´ë“œ] í•œêµ­ì–´ ì¸ì‹ì´ ë” ê°•ë ¥í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        prompt = self._get_highlight_prompt(text)

        for attempt in range(max_attempts):
            for model_name in self.model_candidates:
                try:
                    response = self.client.models.generate_content(
                        model=model_name,
                        contents=prompt,
                        config=types.GenerateContentConfig(
                            response_mime_type="application/json",
                            temperature=0.8, # ì°½ì˜ì ì¸ êµ¬ê°„ ì„ ì •ì„ ìœ„í•´ ì•½ê°„ ìƒí–¥
                        ),
                    )

                    return self._safe_parse_json(response.text)

                except Exception as e:
                    err = str(e).lower()
                    print(f"   âŒ {model_name} ì—ëŸ¬: {err[:80]}")

                    if "quota" in err or "429" in err:
                        self.disabled_keys.add(self.api_keys[self.current_key_idx])
                        self._rotate_key()
                        time.sleep(15)
                        break # ë‹¤ìŒ í‚¤ë¡œ ì¬ì‹œë„

                    if "404" in err:
                        continue # ë‹¤ìŒ ëª¨ë¸ í›„ë³´ë¡œ ì‹œë„

                    time.sleep(5)

            if attempt < max_attempts - 1:
                time.sleep(10)

        return {"highlights": []}

    def _get_highlight_prompt(self, transcript):
        """[ì—…ê·¸ë ˆì´ë“œ] 2.5ì˜ ì§€ëŠ¥ì„ í™œìš©í•˜ëŠ” ê³ ì„±ëŠ¥ í”„ë¡¬í”„íŠ¸"""
        return f"""
# ROLE: ì „ì„¤ì ì¸ ì˜ìƒ í¸ì§‘ì
ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ë‹¤ìŒ ëŒ€ë³¸ì—ì„œ ì‹œì²­ìë“¤ì˜ ëˆˆì„ ì‚¬ë¡œì¡ì„ 'ìµœê³ ì˜ ìˆœê°„' 3~5ê°œë¥¼ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤.

# MISSION:
- íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„(ì‹œì‘~ì¢…ë£Œ)ì„ ì„ ì •í•˜ì„¸ìš”.
- ì„ ì • ì´ìœ (reason)ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

# SELECTION CRITERIA:
1. ê°ì • í­ë°œ (í¬ê²Œ ì›ƒê±°ë‚˜, ë†€ë¼ê±°ë‚˜, ë‹¹í™©í•˜ëŠ” ìˆœê°„)
2. í•µì‹¬ ì •ë³´ (ì²­ì¤‘ì´ ì•Œì•„ì•¼ í•  ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸)
3. ìŠ¤í† ë¦¬ ë°˜ì „ (ì‚¬ê±´ì˜ íë¦„ì´ ê¸‰ë³€í•˜ëŠ” ì§€ì )

# TRANSCRIPT:
{transcript}

# OUTPUT FORMAT (JSON ONLY):
{{
  "highlights": [
    {{
      "start": "HH:MM:SS",
      "end": "HH:MM:SS",
      "category": "ì›ƒìŒ/ì •ë³´/ì¶©ê²©/êµí›ˆ",
      "reason": "ì„ ì • ì´ìœ ë¥¼ ì§§ê³  ê°•ë ¬í•˜ê²Œ ì„¤ëª…",
      "confidence_score": 0.0-1.0
    }}
  ]
}}
"""

    def _safe_parse_json(self, raw_text):
        if not raw_text: return {"highlights": []}
        try:
            return json.loads(raw_text)
        except json.JSONDecodeError:
            # ë§ˆí¬ë‹¤ìš´ ë° ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±° ê°•í™”
            cleaned = re.sub(r"```json\s*|```\s*", "", raw_text.strip())
            match = re.search(r"\{.*\}", cleaned, re.DOTALL)
            if match:
                try: return json.loads(match.group())
                except: pass
        return {"highlights": []}

# --------------------------------------------------
# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ë¶€
# --------------------------------------------------
if __name__ == "__main__":
    llm = LLMInterface()
    sample = "[00:00:10] ì™€! ì§„ì§œ ëŒ€ë°•ì´ë‹¤! [00:01:20] ì—¬ê¸°ì„œë¶€í„°ê°€ ì§„ì§œ ì¤‘ìš”í•œ ë‚´ìš©ì´ì—ìš”."
    print(llm.analyze_full_session(sample))
