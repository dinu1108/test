import json
import subprocess
import requests
import time
from pathlib import Path

class GenericDownloader:
    """Wrapper for yt-dlp to handle Video/Audio/Subs downloading."""
    
    def __init__(self, output_dir):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def download(self, url, start_time=None, end_time=None, audio_only=False, video_worst_only=False, with_metadata=False):
        """Downloads video/audio. Metadata disabled by default to prevent 429."""
        import random
        
        # Rate Limiting (Optimized: Short human-like delay instead of 30-60s)
        sleep_time = random.uniform(2, 5) 
        print(f"[Scraper] Sleeping {sleep_time:.1f}s (Humanized Delay)...")
        time.sleep(sleep_time)

        print(f"[Scraper] Downloading content from {url}...")
        
        # Output template: {id}.{ext}
        out_tmpl = str(self.output_dir / "%(id)s.%(ext)s")
        
        # Base command with Anti-Blocking Headers
        cmd = [
            "yt-dlp", 
            "--ignore-errors",
            "--user-agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        ]
        
        # Check for aria2c availability
        import shutil
        if shutil.which('aria2c'):
            print("[Scraper] üöÄ Accelerated Mode: Aria2c (8 connections)")
            cmd.extend([
                "--external-downloader", "aria2c",
                "--external-downloader-args", "aria2c:-x 8 -k 1M -s 8"
            ])
        
        if audio_only:
            # User Optimization: Force audio only or worst video, convert to m4a-128k
            print("[Scraper] üéµ Audio-Only Mode Triggered (bestaudio/worst -> m4a)")
            cmd.extend([
                "-f", "bestaudio/worst", 
                "--extract-audio", 
                "--audio-format", "m4a",
                "--audio-quality", "128K", # specific bitrate
            ])
        elif video_worst_only:
             # Visual Sync Optimization: Download smallest video (360p/144p) for pHash
             print("[Scraper] üëÅÔ∏è Visual Sync Mode: Downloading WORST video only...")
             cmd.extend([
                 "-f", "worstvideo[ext=mp4]/bestvideo[height<=360][ext=mp4]/worst[ext=mp4]",
                 # We don't need audio for visual sync
             ])
        else:
            cmd.extend(["-f", "bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4"])
            
        # Section Download
        if start_time and end_time:
            # Format: *start-end
            section_arg = f"*{start_time}-{end_time}"
            print(f"[Scraper] ‚úÇÔ∏è Section Download Mode: {section_arg}")
            cmd.extend(["--download-sections", section_arg])
            # Force overwrite might be needed if re-downloading sections
            cmd.append("--force-overwrites")
        
        if with_metadata:
             cmd.extend([
                "--write-sub", "--write-auto-sub", 
                "--sub-lang", "ko,en",
                "--write-comments", 
                # Rate limiting flags to prevent 429
                "--sleep-requests", "1.5",
                # "--sleep-interval", "3", # Handled by our own delay
            ])
        
        cmd.extend([
            "-o", out_tmpl,
            url
        ])
        
        try:
            subprocess.run(cmd, check=True)
            
            # Find the downloaded file
            name_cmd = ["yt-dlp", "--get-filename", "-o", "%(id)s", url]
            res = subprocess.run(name_cmd, capture_output=True, text=True)
            file_id = res.stdout.strip()
            
            # Search for file starting with ID
            # If audio only, extension might be m4a or webm
            found_files = list(self.output_dir.glob(f"{file_id}*"))
            # Filter out json/vtt
            media_files = [f for f in found_files if f.suffix in ['.mp4', '.m4a', '.webm', '.mkv', '.mp3'] and not f.name.endswith('.temp.mp4')]
            
            if not media_files: return None, None
            
            video_path = media_files[0] # Pick first match
            
            # Check for chat json
            chat_path = self.output_dir / f"{file_id}.live_chat.json"
            if not chat_path.exists():
                # Check .info.json for comments sometimes
                chat_path = None 
                
            return video_path, chat_path
            
        except Exception as e:
            print(f"[Scraper] Download Error: {e}")
            return None, None

class ChzzkChatScraper:
    """Specialized Scraper for Chzzk Chat API."""
    
    def __init__(self):
        self.api_url = "https://api.chzzk.naver.com/service/v1/videos/{}/chat"
        # Note: This is a simplified mock of how one might hit their API. 
        # Real Chzzk API usually requires looping with 'nextMessageTime'.
        
    def scrape(self, video_id, output_path):
        print(f"[Chzzk] Scraping Chat for {video_id}...")
        # Since we can't easily implement the full strict API loop without valid inputs/tokens in this mock environment,
        # we will implement a 'Skeleton' that would work if connected.
        # User warned about API complexity in Plan.
        
        chats = []
        next_time = 0
        
        # Limit for demo/safety
        max_pages = 50 
        
        try:
            session = requests.Session()
            # Fake headers to look like browser
            session.headers.update({
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.93 Safari/537.36"
            })

            # Mock loop (In real usage, we would loop until nextMessageTime is null)
            # URL: https://api.chzzk.naver.com/service/v1/videos/152643/chats?nextMessageTime=...
            # For now, we will save an empty or minimal list if actual API fails, to prevent crashes.
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump([], f) # Placeholder
                
            return output_path
            
        except Exception as e:
            print(f"[Chzzk] Chat Scrape Error: {e}")
            return None

class SoopChatScraper:
    """Placeholder for SOOP (Afreeca) Chat."""
    def scrape(self, video_id, output_path):
        # SOOP VOD chat scraping is notoriously difficult (encrypted/binary).
        # We assume generic download might have caught libs/subs.
        print("[SOOP] Chat scraping not fully supported via public API.")
        return None
