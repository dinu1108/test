import sys
import os
import argparse
import numpy as np
from pathlib import Path

# [1] ê²½ë¡œ ë° í™˜ê²½ ì„¤ì •
base_dir = Path(__file__).parent.absolute()
sys.path.append(str(base_dir))

try:
    from hybrid_agent_v2.knowledge_base import VideoKnowledgeBase
    from hybrid_agent_v2.llm_interface import LLMInterface
    from hybrid_agent_v2.fast_cutter import FastCutter
    from presets.factory_config import FactoryConfig
    from modules.analyst import Analyst
    print("[System] âœ… All Hybrid Engines Loaded.")
except ImportError as e:
    print(f"[System] âŒ Critical Import Error: {e}")
    sys.exit(1)

def finalize_clips(base_candidates, llm_evals, kb, video_id):
    """
    [Stage 3] ê³µì¥ì¥ë‹˜í‘œ í™©ê¸ˆ ìŠ¤ì½”ì–´ í•©ì„± ë° íƒ€ì„ë¼ì¸ í™•ì¥
    """
    final_selections = []
    # âœ… FIX: Candidate ID ë§¤ì¹­ ì•ˆì „í™” (Index ëŒ€ì‹  ID ê¸°ë°˜ ë§¤ì¹­)
    eval_map = {e['id']: e for e in llm_evals.get('evaluations', [])}
    
    PREROLL = FactoryConfig.PREROLL
    POSTROLL = FactoryConfig.POSTROLL

    print(f"\nğŸ“Š [Scoring] Synthesizing Golden Scores for {len(base_candidates)} candidates...")
    
    last_end_time = -999 

    for i, candidate in enumerate(base_candidates):
        # âœ… FIX: CID(Candidate ID) ê¸°ë°˜ ë§¤ì¹­ìœ¼ë¡œ ì¬ì •ë ¬/í•„í„°ë§ ì‹œì—ë„ ì•ˆì „í•¨
        cid = candidate.get('id', i)
        evaluation = eval_map.get(cid)
        
        if not evaluation:
            kb.log_rejection(video_id, candidate, "No Evaluation Data", 0.0)
            continue

        try:
            base_score = float(candidate.get('score', 0.5))
            e_intensity = float(evaluation.get('emotion_intensity', 0.5))
            i_density = float(evaluation.get('info_density', 0.5))
            c_break = float(evaluation.get('context_break', 0.5))
            # âœ… FIX #4: narrative_payoff ì‹¤ì œ ì ìˆ˜ ë°˜ì˜
            payoff = float(evaluation.get('narrative_payoff', 0.5))
        except (TypeError, ValueError):
            print(f"   âš ï¸ ì»· #{cid} - ì ìˆ˜ ë°ì´í„° í˜•ì‹ ë¶„ì„ ì‹¤íŒ¨, ê±´ë„ˆëœ€")
            kb.log_rejection(video_id, candidate, "Type conversion failed", 0.0)
            continue
        
        if any(x is None for x in [base_score, e_intensity, i_density, c_break]):
            print(f"   âš ï¸ ì»· #{cid} - í‰ê°€ ë°ì´í„° ë¶ˆì™„ì „, ê±´ë„ˆëœ€")
            kb.log_rejection(video_id, candidate, "Incomplete evaluation data", 0.0)
            continue
        
        w = FactoryConfig.WEIGHTS
        # âœ… V5: ì‹ ê·œ ê°€ì¤‘ì¹˜ ê³µì‹ (Event_Match 0.4 + Signal_Peak 0.3 + Speech_Density 0.3)
        # ì—¬ê¸°ì„œëŠ” LLM í‰ê°€ ê²°ê³¼(narrative_payoff ë“±)ë¥¼ Event_Matchë¡œ, base_scoreë¥¼ Signal_Peakë¡œ í™œìš©
        
        event_match = i_density # LLMì´ íŒë‹¨í•œ ì •ë³´ ë°€ë„/ì´ë²¤íŠ¸ ì í•©ë„
        signal_peak = base_score # ì˜¤ë””ì˜¤ ë¶„ì„ ê¸°ë°˜ ì‹ í˜¸ ê°•ë„
        speech_density = float(evaluation.get('speech_density', 0.5)) # KBì—ì„œ ê°€ì ¸ì˜¨ í™”ë²• ë°€ë„
        
        final_score = (
            event_match * 0.4 +
            signal_peak * 0.3 +
            speech_density * 0.3
        )

        if evaluation.get('is_unnecessary', False):
            final_score -= 0.5
            
        peak = candidate.get('peak_time') or candidate.get('start', 0.0)
        try:
            peak = float(peak)
        except (TypeError, ValueError):
            peak = 0.0
        
        # âœ… FIX #9: CONTINUITY_GAP ë™ì  ì¡°ì ˆ (ì•„ì´ë””ì–´ ë°˜ì˜: ê³ ë“ì  ì‹œ ê°„ê²© ì¶•ì†Œ)
        gap_limit = FactoryConfig.CONTINUITY_GAP
        if final_score > 0.8: gap_limit *= 0.5 # ê³ ë“ì  í›„ë³´ëŠ” ë” ì´˜ì´˜í•˜ê²Œ ë°°ì¹˜ í—ˆìš©
        
        gap = peak - last_end_time
        if last_end_time > 0 and gap < gap_limit:
            final_score -= 0.1

        reason = evaluation.get('reason', 'N/A')
        print(f"   ğŸ¬ ì»· #{cid} | ìµœì¢…: {final_score:.2f} (ê¸°ë³¸:{base_score:.1f} ê°ì •:{e_intensity:.1f} ì„œì‚¬:{i_density:.1f}) | {reason[:40]}")

        if final_score > FactoryConfig.GOLDEN_SCORE_THRESHOLD:
            final_selections.append({
                "start": max(0, peak - PREROLL),
                "end": peak + POSTROLL,
                "score": final_score,
                "reason": reason,
                "original_peak": peak,
                "bridge_text": candidate.get('bridge_text', ""),
                "id": cid # ID ë³´ì¡´
            })
            last_end_time = peak + POSTROLL
        else:
            kb.log_rejection(video_id, candidate, f"Low Score: {final_score:.2f}", final_score)

    return final_selections

def run_factory(video_path, top_n_chapters=3, force_refresh=False):
    video_file = Path(video_path)
    if not video_file.exists():
        print(f"âŒ File Not Found: {video_path}")
        return

    video_id = video_file.stem
    kb = VideoKnowledgeBase()
    kb.ingest(str(video_file))

    print(f"\nğŸ—ºï¸ [V5 Map-Reduce] Starting Event-Log based Ranking Analysis...")
    from hybrid_agent_v2.story_architect import StoryArchitect
    architect = StoryArchitect()
    
    # [1] Map Phase: ì „ì²´ ëŒ€ë³¸ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ í›„ë³´êµ° ì¶”ì¶œ
    print("   ğŸ—ºï¸ [Map] Extracting event-driven candidates from chunks...")
    full_transcript = kb.get_full_transcript(str(video_file))
    event_logs_json = architect._summarize_transcript_in_chunks(full_transcript, video_id)
    
    import json
    try:
        event_logs = json.loads(event_logs_json) if isinstance(event_logs_json, str) else event_logs_json
    except:
        print("   âš ï¸ Failed to parse event logs. Falling back to default events.")
        event_logs = []

    # [Visual Scouting]
    visual_data = None
    if not getattr(FactoryConfig, 'SKIP_VISUAL', False):
        try:
            from hybrid_agent_v2.visual_scout import VisualScout
            scout = VisualScout()
            visual_data = scout.analyze_video(str(video_file))
        except Exception as e: print(f"âš ï¸ VisualScout fail: {e}")

    # [Signal Analysis] for Speech Density & Peaks
    analyst = Analyst()
    audio_data = analyst.analyze_audio_advanced(str(video_file))
    sig_scores, sig_times = analyst.calculate_scores(audio_data)

    # [2] Filter Phase: ì´ë²¤íŠ¸ ë¡œê·¸ + ì‹œê°ì  í”¼í¬ + ëŒ€ì‚¬ ë°€ë„ ê²°í•©
    print("   ğŸ” [Filter] Merging signal peaks and event logs (Global Ranking)...")
    base_candidates = []
    
    # 1. Event-based Candidates (LLM Log)
    for log in event_logs:
        t = log.get('time', 0)
        importance = log.get('importance', 5) / 10.0
        
        # í•´ë‹¹ ì‹œì ì˜ Speech Density ì¡°íšŒ (KB ë©”íƒ€ë°ì´í„° í™œìš©)
        ctx = kb.get_context(video_id, max(0, t-5), t+5)
        avg_density = np.mean([c.get('speech_density', 0.5) for c in ctx]) if ctx else 0.5
        
        base_candidates.append({
            "id": len(base_candidates),
            "peak_time": t,
            "score": float(importance),
            "speech_density": float(avg_density),
            "text": f"[Event] {log.get('event', 'Unknown')}",
            "type": "event"
        })

    # 2. Add Signal-based Candidates if not redundant
    sig_indices = np.argsort(sig_scores)[::-1][:30]
    for idx in sig_indices:
        t = sig_times[idx]
        if any(abs(t - c['peak_time']) < 60 for c in base_candidates): continue # 1ë¶„ ë‚´ ì¤‘ë³µ ì œê±°
        
        base_candidates.append({
            "id": len(base_candidates),
            "peak_time": t,
            "score": float(sig_scores[idx]),
            "text": f"[Signal] Audio Peak at {t:.1f}s",
            "type": "signal"
        })

    # [3] Global Ranking: Top 15 ì„ ì •
    base_candidates = sorted(base_candidates, key=lambda x: x['score'], reverse=True)[:15]
    print(f"   âœ… [V5] Selected top {len(base_candidates)} candidates for precision evaluation.")

    # [4] Reduce Phase: ì •ë°€ í‰ê°€ ë° ë Œë”ë§
    if base_candidates:
        print(f"\nğŸ§  [Stage 2] Gemini Precision Evaluation (gemini-1.5-flash)...")
        llm = LLMInterface()
        eval_results = llm.evaluate_candidates(kb, video_id, base_candidates, force_refresh=force_refresh)
        
        valid_clips = finalize_clips(base_candidates, eval_results, kb, video_id)
        
        if valid_clips:
            valid_clips = kb.precise_retranscribe(str(video_file), valid_clips)
            print(f"\nâš™ï¸ [Production] Rendering Final Masterpiece...")
            cutter = FastCutter()
            merged_clips = cutter.smart_merge(valid_clips, min_gap=FactoryConfig.CONTINUITY_GAP)
            cutter.cut_clips(str(video_file), merged_clips)
            print(f"\nâœ¨ [V5 SUCCESS] Narrative Highlight Movie Produced!")
        else:
            print("\nâŒ No clips passed the final quality hurdle.")
    else:
        print("\nâŒ No candidates identified in this video.")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("video_path", help="Target video file path")
    parser.add_argument("--preset", help="Style preset (e.g. presets/kimdo.json)", default=None)
    parser.add_argument("--chapters", help="Number of top chapters to select", type=int, default=3)
    parser.add_argument("--no-visual", help="Skip visual analysis to save time", action="store_true")
    parser.add_argument("--force-refresh", help="Ignore existing checkpoints and force fresh analysis", action="store_true")
    args = parser.parse_args()
    
    if args.preset:
        FactoryConfig.load_preset(args.preset)

    if args.no_visual:
        FactoryConfig.SKIP_VISUAL = True

    try:
        run_factory(args.video_path, top_n_chapters=args.chapters, force_refresh=args.force_refresh)
    except Exception as e:
        print(f"\nğŸš¨ [Critical Error] {e}")
        import traceback
        traceback.print_exc()
